import streamlit as st
import fitz  # PyMuPDF
from supabase import create_client, Client
import google.generativeai as genai
from openai import OpenAI
import json
import logging

# --- Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---
@st.cache_resource
def init_supabase_client() -> Client:
    try:
        return create_client(st.secrets["SUPABASE_URL"], st.secrets["SUPABASE_KEY"])
    except KeyError as e:
        st.error(f"'{e.args[0]}'ë¥¼ secrets.toml íŒŒì¼ì— ì„¤ì •í•´ì£¼ì„¸ìš”.")
        logging.error(f"Secrets ì„¤ì • ì˜¤ë¥˜: {e}")
        st.stop()

# --- Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---
@st.cache_resource
def init_gemini_model():
    try:
        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
        return genai.GenerativeModel("gemini-2.5-pro")
    except KeyError as e:
        st.error(f"'{e.args[0]}'ë¥¼ secrets.toml íŒŒì¼ì— ì„¤ì •í•´ì£¼ì„¸ìš”.")
        logging.error(f"Secrets ì„¤ì • ì˜¤ë¥˜: {e}")
        st.stop()
    except Exception as e:
        st.error("Gemini ëª¨ë¸ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ê°€ ìœ íš¨í•œì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        logging.error(f"Gemini ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        st.stop()

# --- OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---
@st.cache_resource
def init_openai_client():
    try:
        client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
        return client
    except KeyError as e:
        st.error(f"'{e.args[0]}'ë¥¼ secrets.toml íŒŒì¼ì— ì„¤ì •í•´ì£¼ì„¸ìš”.")
        logging.error(f"Secrets ì„¤ì • ì˜¤ë¥˜: {e}")
        st.stop()

# --- PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ---
@st.cache_data
def extract_text_from_pdf(file_content: bytes) -> str:
    try:
        with fitz.open(stream=file_content, filetype="pdf") as doc:
            text = "".join([page.get_text() for page in doc])
        return text
    except Exception as e:
        st.error(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return ""

# --- í…ìŠ¤íŠ¸ ë¶„í•  í•¨ìˆ˜ (ë¬¸ììˆ˜ ê¸°ì¤€) ---
def split_text_into_chunks(text: str, max_chars: int = 1000) -> list:
    paragraphs = text.split("\n")
    chunks = []
    current_chunk = ""

    for para in paragraphs:
        if len(current_chunk) + len(para) + 1 <= max_chars:
            current_chunk += para + "\n"
        else:
            if current_chunk.strip():
                chunks.append(current_chunk.strip())
            current_chunk = para + "\n"
    if current_chunk.strip():
        chunks.append(current_chunk.strip())

    return chunks

# --- OpenAI ì„ë² ë”© ìƒì„± í•¨ìˆ˜ ---
def get_embedding_openai(text: str):
    try:
        response = openai_client.embeddings.create(input=text, model="text-embedding-3-large")
        return response.data[0].embedding
    except Exception as e:
        st.error(f"ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {e}")
        return None

# --- Supabaseì— chunk + ì„ë² ë”© ì €ì¥ ---
def save_vector_chunks(filename: str, text: str):
    chunks = split_text_into_chunks(text, max_chars=1000)
    for chunk in chunks:
        emb = get_embedding_openai(chunk)
        if emb:
            try:
                supabase.table("vector_chunks").insert({
                    "filename": filename,
                    "chunk_text": chunk,
                    "embedding": emb
                }).execute()
            except Exception as e:
                st.error(f"ë²¡í„° ì²­í¬ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

# --- PDF í…ìŠ¤íŠ¸ì™€ vector_chunks ì €ì¥ í†µí•© ---
def save_pdf_and_vectors(filename: str, content: str):
    try:
        supabase.table("pdf_texts").insert({"filename": filename, "content": content}).execute()
        save_vector_chunks(filename, content)
    except Exception as e:
        st.error(f"PDF ì €ì¥ ë° ë²¡í„° ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")

# --- Supabase ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ í•¨ìˆ˜ ---
def query_similar_chunks(question: str, top_k=5) -> list:
    question_emb = get_embedding_openai(question)
    if not question_emb:
        return []

    try:
        response = supabase.rpc("match_chunks", {
            "query_embedding": question_emb,
            "match_count": top_k
        }).execute()

        if response.data is None or len(response.data) == 0:
            return []

        return [r["chunk_text"] for r in response.data]
    except Exception as e:
        st.error(f"ë²¡í„° ê²€ìƒ‰ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

# --- ìƒì„±í˜• AI ë‹µë³€ ìƒì„± í•¨ìˆ˜ (RAG ë°©ì‹) ---
def ask_question_with_rag(question: str, _model, _client, _api_choice: str) -> str:
    top_chunks = query_similar_chunks(question, top_k=5)
    if not top_chunks:
        return "ê´€ë ¨ëœ ë‚´ìš©ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
    context = "\n---\n".join(top_chunks)
    prompt = f"""ë‹¤ìŒì€ ê´€ë ¨ ì°¸ê³  ë¬¸ì„œ ë‚´ìš©ì…ë‹ˆë‹¤.
{context}

ì•„ë˜ ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”:
{question}
"""
    try:
        if _api_choice == "Gemini":
            response = _model.generate_content(prompt)
            return response.text.strip()
        else:
            response = _client.chat.completions.create(
                model="gpt-4.1-nano",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=1024,
                temperature=0.7,
            )
            return response.choices[0].message.content.strip()
    except Exception as e:
        return f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

# --- Gemini ìš”ì•½ í•¨ìˆ˜ ---
@st.cache_data
def summarize_text_gemini(text_chunk: str, _model) -> str:
    prompt = f"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì¤˜:\n\n{text_chunk}"
    try:
        response = _model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        return f"ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

# --- OpenAI ìš”ì•½ í•¨ìˆ˜ ---
@st.cache_data
def summarize_text_openai(text_chunk: str, _client: OpenAI) -> str:
    prompt = f"ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì¤˜:\n\n{text_chunk}"
    try:
        response = _client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=512,
            temperature=0.3,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

# --- í€´ì¦ˆ ìƒì„± í•¨ìˆ˜ (ìš”ì•½ í…ìŠ¤íŠ¸ ê¸°ë°˜) ---
def generate_quiz_with_summary(text: str, _model, _client, _api_choice: str) -> str:
    chunks = split_text_into_chunks(text, max_chars=3000)
    summaries = []
    for chunk in chunks:
        if _api_choice == "Gemini":
            summary = summarize_text_gemini(chunk, _model)
        else:
            summary = summarize_text_openai(chunk, _client)
        summaries.append(summary)
    combined_summary = "\n".join(summaries)

    prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°ê´€ì‹ ë¬¸ì œ 1ê°œë¥¼ ë§Œë“¤ì–´ì¤˜.
ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì„ ì •í™•íˆ ì§€ì¼œì„œ ì‘ë‹µí•´ì¤˜.

[í˜•ì‹]
ë¬¸ì œ: [ë¬¸ì œ ë‚´ìš©]
1. [ë³´ê¸° 1]
2. [ë³´ê¸° 2]
3. [ë³´ê¸° 3]
4. [ë³´ê¸° 4]
ì •ë‹µ: [ì •ë‹µ ë³´ê¸°ì˜ ë‚´ìš©]

[í…ìŠ¤íŠ¸]
{combined_summary}
"""

    try:
        if _api_choice == "Gemini":
            response = _model.generate_content(prompt)
            return response.text.strip()
        else:
            response = _client.chat.completions.create(
                model="gpt-4.1-nano",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=1024,
                temperature=0.7,
            )
            return response.choices[0].message.content.strip()
    except Exception as e:
        return f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

# --- í€´ì¦ˆ ì €ì¥ ---
def save_quiz(q: str, opts: list, ans: str):
    try:
        supabase.table("quiz_questions").insert({
            "question": q,
            "options": json.dumps(opts, ensure_ascii=False),
            "answer": ans
        }).execute()
        st.success("âœ… ë¬¸ì œê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.cache_data.clear()
    except Exception as e:
        st.error(f"Supabaseì— í€´ì¦ˆ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# --- í€´ì¦ˆ ëª©ë¡ ì¡°íšŒ ---
@st.cache_data
def get_quizzes():
    try:
        response = supabase.table("quiz_questions").select("*").execute()
        return response.data
    except Exception as e:
        st.error(f"í€´ì¦ˆ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

# --- Supabase ì´ˆê¸°í™” ---
supabase = init_supabase_client()
gemini_model = init_gemini_model()
openai_client = init_openai_client()

# --- Streamlit UI ì„¤ì • ---
st.set_page_config(page_title="PDF ê¸°ë°˜ Q&A RAG ì‹œìŠ¤í…œ", layout="wide")
st.title("ğŸ“š íšŒë¡œìš©ì–´ EASY AI - ë‚´ ì†ì•ˆì˜ ë§ì¶¤í˜• í•™ìŠµ ì½”ì¹˜")

api_choice = st.sidebar.radio("AI ëª¨ë¸ ì„ íƒ", ("Gemini", "OpenAI"))
menu = st.sidebar.selectbox("ë©”ë‰´ ì„ íƒ", ["ğŸ“„ PDF ì—…ë¡œë“œ", "â“ ì§ˆì˜ì‘ë‹µ", "ğŸ“ ì‹œí—˜ë¬¸ì œ ì¶œì œ", "ğŸ“‘ ë¬¸ì œ ë³´ê¸°"])

if menu == "ğŸ“„ PDF ì—…ë¡œë“œ":
    st.subheader("ğŸ“„ PDF ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.", type="pdf")

    if uploaded_file:
        file_bytes = uploaded_file.getvalue()
        pdf_text = extract_text_from_pdf(file_bytes)

        if f"processed_{uploaded_file.name}" not in st.session_state:
            with st.spinner("PDF í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ê³  ë²¡í„° ì„ë² ë”©ì„ ì €ì¥í•˜ëŠ” ì¤‘..."):
                save_pdf_and_vectors(uploaded_file.name, pdf_text)
            st.session_state[f"processed_{uploaded_file.name}"] = True
            st.success("âœ… PDF í…ìŠ¤íŠ¸ì™€ ë²¡í„° ì„ë² ë”© ì €ì¥ ì™„ë£Œ!")
        else:
            st.info("â„¹ï¸ ì´ì „ì— ì²˜ë¦¬ëœ PDFì…ë‹ˆë‹¤. ìºì‹œëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

    st.divider()

elif menu == "â“ ì§ˆì˜ì‘ë‹µ":
    st.subheader("â“ ì§ˆì˜ì‘ë‹µ")
    try:
        pdf_list_response = supabase.table("pdf_texts").select("id, filename").execute()
        pdf_list = pdf_list_response.data
    except Exception as e:
        st.error(f"ì €ì¥ëœ PDF ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        pdf_list = []

    if pdf_list:
        pdf_choice = st.selectbox("ë¬¸ì„œ ì„ íƒ", pdf_list, format_func=lambda x: x['filename'])
        if pdf_choice:
            try:
                selected_pdf_content_response = supabase.table("pdf_texts").select("content").eq("id", pdf_choice['id']).single().execute()
                selected_pdf_content = selected_pdf_content_response.data['content']
            except Exception as e:
                st.error(f"ì„ íƒëœ PDF ë‚´ìš©ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                selected_pdf_content = ""

            user_q = st.text_input("PDF ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”:", placeholder="ì˜ˆ: ì´ ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì€ ë¬´ì—‡ì¸ê°€ìš”?")
            if user_q and selected_pdf_content:
                with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                    answer = ask_question_with_rag(
                        user_q,
                        _model=gemini_model,
                        _client=openai_client,
                        _api_choice=api_choice)
                    st.info(f"ğŸ’¬ ë‹µë³€: {answer}")
    else:
        st.info("ë¨¼ì € 'ğŸ“„ PDF ì—…ë¡œë“œ' ë©”ë‰´ì—ì„œ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    st.divider()

elif menu == "ğŸ“ ì‹œí—˜ë¬¸ì œ ì¶œì œ":
    st.subheader("ğŸ§  í€´ì¦ˆ ìƒì„± ë° ì €ì¥")
    try:
        pdf_list_response = supabase.table("pdf_texts").select("id, filename").execute()
        pdf_list = pdf_list_response.data
    except Exception as e:
        st.error(f"ì €ì¥ëœ PDF ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        pdf_list = []

    if pdf_list:
        pdf_choice = st.selectbox("ì¶œì œí•  ë¬¸ì„œ ì„ íƒ", pdf_list, format_func=lambda x: x['filename'])
        if st.button("ê°ê´€ì‹ ë¬¸ì œ ìƒì„±í•˜ê¸°", type="primary"):
            if pdf_choice:
                try:
                    selected_pdf_content_response = supabase.table("pdf_texts").select("content").eq("id", pdf_choice['id']).single().execute()
                    selected_pdf_content = selected_pdf_content_response.data['content']
                except Exception as e:
                    st.error(f"ì„ íƒëœ PDF ë‚´ìš©ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    selected_pdf_content = ""

                if selected_pdf_content:
                    with st.spinner("í€´ì¦ˆë¥¼ ìƒì„±í•˜ëŠ” ì¤‘..."):
                        quiz_text = generate_quiz_with_summary(
                            selected_pdf_content,
                            _model=gemini_model,
                            _client=openai_client,
                            _api_choice=api_choice)
                        try:
                            lines = [line.strip() for line in quiz_text.splitlines() if line.strip()]
                            question = ""
                            options = []
                            answer = ""

                            for line in lines:
                                if line.startswith("ë¬¸ì œ:"):
                                    question = line.replace("ë¬¸ì œ:", "").strip()
                                elif line.startswith(("1.", "2.", "3.", "4.")):
                                    options.append(line[2:].strip())
                                elif line.startswith("ì •ë‹µ:"):
                                    answer = line.replace("ì •ë‹µ:", "").strip()

                            if question and len(options) == 4 and answer:
                                st.write("**ìƒì„±ëœ ë¬¸ì œ ë¯¸ë¦¬ë³´ê¸°**")
                                st.code(quiz_text, language='text')
                                save_quiz(question, options, answer)
                            else:
                                st.error("âŒ ë¬¸ì œ íŒŒì‹± ì‹¤íŒ¨. ì„ íƒí•œ AIê°€ ìƒì„±í•œ í€´ì¦ˆ í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”.")
                                st.code(quiz_text, language='text')

                        except Exception as e:
                            st.error(f"âŒ ë¬¸ì œ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                            st.write("AIê°€ ìƒì„±í•œ ì›ë³¸ í…ìŠ¤íŠ¸:")
                            st.code(quiz_text, language='text')
                else:
                    st.info("ë¨¼ì € ë¬¸ì„œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
    else:
        st.info("ë¨¼ì € 'ğŸ“„ PDF ì—…ë¡œë“œ' ë©”ë‰´ì—ì„œ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    st.divider()

elif menu == "ğŸ“‘ ë¬¸ì œ ë³´ê¸°":
    st.subheader("ğŸ“‹ ì €ì¥ëœ ë¬¸ì œ ëª©ë¡")
    quiz_data = get_quizzes()
    if quiz_data:
        for q in reversed(quiz_data):
            st.markdown(f"**Q. {q['question']}**")
            try:
                options_list = json.loads(q["options"]) if isinstance(q["options"], str) else q["options"]
            except json.JSONDecodeError:
                options_list = []

            correct_answer_text = q['answer'].strip()
            for opt in options_list:
                if opt.strip() == correct_answer_text:
                    st.markdown(f"- {opt} âœ…")
                else:
                    st.markdown(f"- {opt}")
            st.markdown("---")
    else:
        st.info("í˜„ì¬ ì €ì¥ëœ ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤.")
